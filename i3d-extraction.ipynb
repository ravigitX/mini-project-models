{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10821213,"sourceType":"datasetVersion","datasetId":6718702},{"sourceId":10891782,"sourceType":"datasetVersion","datasetId":6752008}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#i3d extraction\n\n!git clone https://github.com/piergiaj/pytorch-i3d.git\n%cd pytorch-i3d\n!pip install torch torchvision numpy pillow tqdm\n\n# Create models directory\n!mkdir -p models\n\n# Download flow_imagenet.pt into models/\n!wget -O /kaggle/working/flow_imagenet.pt https://www.dropbox.com/s/7w4z5q9fowcp9x5/flow_imagenet.pt?dl=1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:47.305132Z","iopub.execute_input":"2025-04-16T06:26:47.305456Z","iopub.status.idle":"2025-04-16T06:26:53.329642Z","shell.execute_reply.started":"2025-04-16T06:26:47.305426Z","shell.execute_reply":"2025-04-16T06:26:53.328452Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'pytorch-i3d' already exists and is not an empty directory.\n/kaggle/working/pytorch-i3d\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n--2025-04-16 06:26:52--  https://www.dropbox.com/s/7w4z5q9fowcp9x5/flow_imagenet.pt?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘/kaggle/working/flow_imagenet.pt’\n\n/kaggle/working/flo     [ <=>                ]  70.00K  --.-KB/s    in 0.06s   \n\n2025-04-16 06:26:53 (1.16 MB/s) - ‘/kaggle/working/flow_imagenet.pt’ saved [71685]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!ls /kaggle/working/pytorch-i3d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:53.330737Z","iopub.execute_input":"2025-04-16T06:26:53.331047Z","iopub.status.idle":"2025-04-16T06:26:53.459521Z","shell.execute_reply.started":"2025-04-16T06:26:53.331020Z","shell.execute_reply":"2025-04-16T06:26:53.458282Z"}},"outputs":[{"name":"stdout","text":"models\tpytorch-i3d\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/pytorch-i3d')\nfrom pytorch_i3d import InceptionI3d\n\n\n\n!wget -O /kaggle/working/flow_imagenet.pt https://github.com/piergiaj/pytorch-i3d/raw/master/models/flow_imagenet.pt\n!file /kaggle/working/flow_imagenet.pt\n!wget -O /kaggle/working/rgb_imagenet.pt https://github.com/piergiaj/pytorch-i3d/raw/master/models/rgb_imagenet.pt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:53.460845Z","iopub.execute_input":"2025-04-16T06:26:53.461161Z","iopub.status.idle":"2025-04-16T06:26:53.483430Z","shell.execute_reply.started":"2025-04-16T06:26:53.461134Z","shell.execute_reply":"2025-04-16T06:26:53.481856Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5e8a9bfb4430>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/pytorch-i3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_i3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInceptionI3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_i3d'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pytorch_i3d'","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"# Final I3D Extraction \n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torchvision.transforms as transforms\nfrom pytorch_i3d import InceptionI3d\n\n# --- Config ---\ndataset_path = '/kaggle/input/shanghaitech-anomaly-detection/dataset/mp'\noutput_dir = '/kaggle/working/I3D_Train_Frame'\nos.makedirs(output_dir, exist_ok=True)\n\n# --- Device Setup ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --- I3D Model Loader (RGB version) ---\ndef load_i3d_model():\n    i3d = InceptionI3d(400, in_channels=3)  # 3 channels for RGB\n    i3d.load_state_dict(torch.load('/kaggle/working/rgb_imagenet.pt'))\n    i3d.to(device)\n    i3d.eval()\n    return i3d\n\n# --- I3D Feature Extractor (1024×7×7) ---\nclass I3DFeatureExtractor(torch.nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.features = torch.nn.Sequential(\n            model.Conv3d_1a_7x7,\n            model.MaxPool3d_2a_3x3,\n            model.Conv3d_2b_1x1,\n            model.Conv3d_2c_3x3,\n            model.MaxPool3d_3a_3x3,\n            model.Mixed_3b,\n            model.Mixed_3c,\n            model.MaxPool3d_4a_3x3,\n            model.Mixed_4b,\n            model.Mixed_4c,\n            model.Mixed_4d,\n            model.Mixed_4e,\n            model.Mixed_4f,\n            model.MaxPool3d_5a_2x2,\n            model.Mixed_5b,\n            model.Mixed_5c\n        )\n\n    def forward(self, x):\n        x = x.unsqueeze(2)  # (N, C, 1, H, W)\n        x = self.features(x)\n        # Get rid of the batch dimension and time dimension but keep 1024×7×7\n        return x.squeeze(0).squeeze(0)  # Remove batch and time dimensions, keep C×H×W\n        print(x.shape)\n\n# --- RGB Frame Preprocessing ---\ndef preprocess_rgb_frame(frame_path):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n    ])\n    img = Image.open(frame_path).convert('RGB')\n    return transform(img).to(device)\n\n# --- Feature Extraction ---\ndef extract_i3d_features(model, dataset_path, output_dir):\n    extractor = I3DFeatureExtractor(model)\n   \n    for video_folder in tqdm(sorted(os.listdir(dataset_path))):\n        # Change from 'optical_flow' to 'frames' directory for RGB frames\n        frames_dir = os.path.join(dataset_path, video_folder, 'frames')\n        if not os.path.exists(frames_dir):\n            continue\n           \n        frame_paths = sorted([os.path.join(frames_dir, f)\n                          for f in os.listdir(frames_dir)\n                          if f.lower().endswith(('.jpg','.png','.jpeg'))])\n       \n        # Create output directory for this video's RGB features\n        video_output_dir = os.path.join(output_dir, video_folder)\n        os.makedirs(video_output_dir, exist_ok=True)\n       \n        for frame_idx, frame_path in enumerate(frame_paths):\n            try:\n                rgb_frame = preprocess_rgb_frame(frame_path)\n                with torch.no_grad():\n                    # This will return a tensor of shape (1024, 7, 7)\n                    features = extractor(rgb_frame.unsqueeze(0)).cpu().numpy()\n               \n                # Save the 1024×7×7 feature tensor directly\n                np.save(os.path.join(video_output_dir, f\"rgb_frame_{frame_idx:04d}.npy\"), features)\n            except Exception as e:\n                print(f\"Error processing {frame_path}: {e}\")\n                continue\n\nif __name__ == \"__main__\":\n    print(\"Loading I3D RGB model...\")\n    i3d = load_i3d_model()\n   \n    print(\"Extracting 1024×7×7 RGB frame features...\")\n    extract_i3d_features(i3d, dataset_path, output_dir)\n   \n    # Verify feature dimensions\n    sample_video = os.listdir(output_dir)[0]\n    sample_frame = os.listdir(os.path.join(output_dir, sample_video))[0]\n    sample_features = np.load(os.path.join(output_dir, sample_video, sample_frame))\n    print(f\"\\nFeature verification:\")\n    print(f\"Shape: {sample_features.shape}\")  # Should be (1024, 7, 7)\n    print(f\"Value range: [{sample_features.min():.3f}, {sample_features.max():.3f}]\")\n   \n    print(f\"\\n✅ RGB frame features with 1024×7×7 dimensions saved in {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:53.484049Z","iopub.status.idle":"2025-04-16T06:26:53.484363Z","shell.execute_reply":"2025-04-16T06:26:53.484236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Flow I3D Extraction","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torchvision.transforms as transforms\nfrom pytorch_i3d import InceptionI3d\n\n# --- Config ---\ndataset_path = '/kaggle/input/shanghaitech-anomaly-detection/dataset/mp'\noutput_dir = '/kaggle/working/I3D_Train_Flow'\nos.makedirs(output_dir, exist_ok=True)\n\n# --- Device Setup ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --- I3D Model Loader (Optical Flow version) ---\ndef load_i3d_model():\n    i3d = InceptionI3d(400, in_channels=2)  # 2 channels for optical flow\n    i3d.load_state_dict(torch.load('/kaggle/working/flow_imagenet.pt'))\n    i3d.to(device)\n    i3d.eval()\n    return i3d\n\n# --- I3D Feature Extractor (1024-D) ---\nclass I3DFeatureExtractor(torch.nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.features = torch.nn.Sequential(\n            model.Conv3d_1a_7x7,\n            model.MaxPool3d_2a_3x3,\n            model.Conv3d_2b_1x1,\n            model.Conv3d_2c_3x3,\n            model.MaxPool3d_3a_3x3,\n            model.Mixed_3b,\n            model.Mixed_3c,\n            model.MaxPool3d_4a_3x3,\n            model.Mixed_4b,\n            model.Mixed_4c,\n            model.Mixed_4d,\n            model.Mixed_4e,\n            model.Mixed_4f,\n            model.MaxPool3d_5a_2x2,\n            model.Mixed_5b,\n            model.Mixed_5c\n        )\n\n    def forward(self, x):\n        x = x.unsqueeze(2)  # (N, C, 1, H, W)\n        x = self.features(x)\n        print(x.shape)\n        return x\n\n# --- Optical Flow Preprocessing ---\ndef preprocess_flow_frame(flow_frame_path):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Lambda(lambda x: x[:2]),  # Take only first two channels\n        transforms.Normalize(mean=[0.5, 0.5], std=[0.5, 0.5])  # Normalize to [-1,1]\n    ])\n    img = Image.open(flow_frame_path)\n    return transform(img).to(device)\n\n# --- Feature Extraction ---\ndef extract_i3d_features(model, dataset_path, output_dir):\n    extractor = I3DFeatureExtractor(model)\n   \n    for video_folder in tqdm(sorted(os.listdir(dataset_path))):\n        flow_dir = os.path.join(dataset_path, video_folder, 'optical_flow')\n        if not os.path.exists(flow_dir):\n            continue\n           \n        flow_paths = sorted([os.path.join(flow_dir, f)\n                          for f in os.listdir(flow_dir)\n                          if f.lower().endswith(('.jpg','.png','.jpeg'))])\n       \n        # Create output directory for this video's flow features\n        video_output_dir = os.path.join(output_dir, video_folder)\n        os.makedirs(video_output_dir, exist_ok=True)\n       \n        for frame_idx, flow_path in enumerate(flow_paths):\n            try:\n                flow_frame = preprocess_flow_frame(flow_path)\n                with torch.no_grad():\n                    features = extractor(flow_frame.unsqueeze(0)).cpu().numpy()  # (1,1024)\n         \n               \n                # Save each frame's flow features as separate numpy file\n                frame_features = features.squeeze()  # shape (1024,)\n                np.save(os.path.join(video_output_dir, f\"flow_frame_{frame_idx:04d}.npy\"), frame_features)\n                #arr=np.load(os.path.join(video_output_dir, f\"flow_frame_{frame_idx:04d}.npy\"))\n                #print(arr.shape)\n            except Exception as e:\n                print(f\"Error processing {flow_path}: {e}\")\n                continue\n\nif __name__ == \"__main__\":\n    print(\"Loading I3D flow model...\")\n    i3d = load_i3d_model()\n   \n    print(\"Extracting 1024-D flow features...\")\n    extract_i3d_features(i3d, dataset_path, output_dir)\n   \n    # Verify feature dimensions\n    sample_video = os.listdir(output_dir)[0]\n    sample_frame = os.listdir(os.path.join(output_dir, sample_video))[0]\n    sample_features = np.load(os.path.join(output_dir, sample_video, sample_frame))\n    print(f\"\\nFeature verification:\")\n    print(f\"Shape: {sample_features.shape}\")  # Should be (1024,7,7)\n    print(f\"First 5 dimensions: {sample_features[:5]}\")\n    print(f\"Value range: [{sample_features.min():.3f}, {sample_features.max():.3f}]\")\n   \n    print(f\"\\n✅ Optical flow features saved as individual files in {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:53.484993Z","iopub.status.idle":"2025-04-16T06:26:53.485283Z","shell.execute_reply":"2025-04-16T06:26:53.485152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Concadnation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport glob\nfrom tqdm import tqdm\n\n# --- Config ---\nrgb_features_dir = '/kaggle/working/I3D_Train_Frame'\nflow_features_dir = '/kaggle/working/I3D_Test_Flow'\noutput_dir = '/kaggle/working/I3D_Combined_Features'\nos.makedirs(output_dir, exist_ok=True)\n\ndef concatenate_rgb_flow_features():\n    \"\"\"\n    Concatenate RGB features (1024×7×7) and flow features (1024×7×7)\n    from two different directories into combined features (2048×7×7).\n    \"\"\"\n    print(\"Concatenating RGB and flow features to create 2048×7×7 feature tensors...\")\n    \n    # Get all video folders from RGB directory\n    rgb_video_folders = set(os.listdir(rgb_features_dir))\n    flow_video_folders = set(os.listdir(flow_features_dir))\n    \n    # Find common videos in both directories\n    common_videos = rgb_video_folders.intersection(flow_video_folders)\n    print(f\"Found {len(common_videos)} videos with both RGB and flow features\")\n    \n    for video_folder in tqdm(sorted(common_videos)):\n        rgb_video_path = os.path.join(rgb_features_dir, video_folder)\n        flow_video_path = os.path.join(flow_features_dir, video_folder)\n        \n        # Get all RGB feature files\n        rgb_feature_files = sorted(glob.glob(os.path.join(rgb_video_path, \"*.npy\")))\n        \n        # Get all flow feature files\n        flow_feature_files = sorted(glob.glob(os.path.join(flow_video_path, \"*.npy\")))\n        \n        if not rgb_feature_files or not flow_feature_files:\n            print(f\"Missing features for {video_folder}\")\n            continue\n        \n        # Create output directory for this video\n        video_output_dir = os.path.join(output_dir, video_folder)\n        os.makedirs(video_output_dir, exist_ok=True)\n        \n        # Process each frame that has both RGB and flow features\n        for i in range(min(len(rgb_feature_files), len(flow_feature_files))):\n            rgb_file = rgb_feature_files[i]\n            flow_file = flow_feature_files[i]\n            \n            # Extract frame number from filename\n            rgb_frame_num = os.path.basename(rgb_file).split('.')[0].split('_')[-1]\n            flow_frame_num = os.path.basename(flow_file).split('.')[0].split('_')[-1]\n            \n            try:\n                # Load RGB and flow features\n                rgb_feat = np.load(rgb_file)\n                flow_feat = np.load(flow_file)\n                \n                # Check shapes\n                if rgb_feat.shape != (1024, 7, 7) or flow_feat.shape != (1024, 7, 7):\n                    print(f\"Unexpected shape: RGB {rgb_feat.shape}, Flow {flow_feat.shape}\")\n                    continue\n                \n                # Concatenate along the channel dimension (first dimension)\n                combined = np.concatenate([rgb_feat, flow_feat], axis=0)\n                \n                # Save combined feature\n                output_path = os.path.join(video_output_dir, f\"combined_frame_{rgb_frame_num}.npy\")\n                np.save(output_path, combined)\n            except Exception as e:\n                print(f\"Error processing frame {rgb_frame_num} of {video_folder}: {e}\")\n                continue\n\nif __name__ == \"__main__\":\n    concatenate_rgb_flow_features()\n    \n    # Verify concatenated features\n    try:\n        sample_video = os.listdir(output_dir)[0]\n        sample_frame = os.listdir(os.path.join(output_dir, sample_video))[0]\n        sample_path = os.path.join(output_dir, sample_video, sample_frame)\n        sample_features = np.load(sample_path)\n        \n        print(f\"\\nFeature verification:\")\n        print(f\"File: {sample_path}\")\n        print(f\"Shape: {sample_features.shape}\")  # Should be (2048, 7, 7)\n        print(f\"Value range: [{sample_features.min():.3f}, {sample_features.max():.3f}]\")\n    except (IndexError, FileNotFoundError) as e:\n        print(f\"Could not verify features: {e}\")\n    \n    print(f\"\\n✅ Combined RGB+Flow features with 2048×7×7 shape saved in {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:26:53.486441Z","iopub.status.idle":"2025-04-16T06:26:53.486849Z","shell.execute_reply":"2025-04-16T06:26:53.486682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\nworking_dir = '/kaggle/working/'\n\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    try:\n        if os.path.isdir(item_path):\n            shutil.rmtree(item_path)\n        else:\n            os.remove(item_path)\n        print(f\"🗑️ Deleted: {item_path}\")\n    except Exception as e:\n        print(f\"⚠️ Could not delete {item_path}: {e}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T06:28:00.175085Z","iopub.execute_input":"2025-04-16T06:28:00.175491Z","iopub.status.idle":"2025-04-16T06:28:02.661537Z","shell.execute_reply.started":"2025-04-16T06:28:00.175461Z","shell.execute_reply":"2025-04-16T06:28:02.660643Z"}},"outputs":[{"name":"stdout","text":"🗑️ Deleted: /kaggle/working/flow_imagenet.pt\n🗑️ Deleted: /kaggle/working/.zip\n🗑️ Deleted: /kaggle/working/.virtual_documents\n🗑️ Deleted: /kaggle/working/rgb_imagenet.pt\n🗑️ Deleted: /kaggle/working/state.db\n🗑️ Deleted: /kaggle/working/pytorch-i3d\n🗑️ Deleted: /kaggle/working/I3D_Features_flowframetrain\n🗑️ Deleted: /kaggle/working/combined_rgb_flow_features\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}