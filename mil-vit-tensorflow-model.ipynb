{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10891782,"sourceType":"datasetVersion","datasetId":6752008}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nfrom IPython.display import clear_output\n\ndef prevent_timeout(minutes=55):\n    \"\"\"\n    Prevents notebook timeout by printing a message every specified number of minutes.\n    Most notebook environments have a 60-90 minute timeout, so the default is set to 55 minutes.\n    \n    Args:\n        minutes (int): Number of minutes between each activity signal\n    \"\"\"\n    seconds = minutes * 60\n    counter = 1\n    \n    print(f\"Timeout prevention started. Will refresh every {minutes} minutes.\")\n    \n    try:\n        while True:\n            time.sleep(seconds)\n            clear_output(wait=True)\n            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n            print(f\"Keeping session alive... Ping #{counter} at {current_time}\")\n            print(f\"Timeout prevention active. Will refresh every {minutes} minutes.\")\n            counter += 1\n    except KeyboardInterrupt:\n        print(\"Timeout prevention stopped.\")\n\n# Run this in a Jupyter notebook cell to start the timeout prevention\n# You can stop it by interrupting the kernel (Kernel > Interrupt) or by pressing Ctrl+C","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:46:17.200606Z","iopub.execute_input":"2025-03-09T13:46:17.200947Z","iopub.status.idle":"2025-03-09T13:46:17.206427Z","shell.execute_reply.started":"2025-03-09T13:46:17.200921Z","shell.execute_reply":"2025-03-09T13:46:17.205571Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nimport numpy as np\n\n# Data Augmentation for Frames\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5] * 3, [0.5] * 3),  # Normalize to mean 0.5, std 0.5\n])\n\nclass FrameDataset(Dataset):\n    def __init__(self, base_folder, transform=None):\n        self.base_folder = base_folder\n        self.transform = transform\n        self.frame_paths = []\n        self.labels = []\n\n        video_folders = sorted([f for f in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, f))])\n        for video_folder in video_folders:\n            frame_folder = os.path.join(base_folder, video_folder, 'frames')\n           \n            if not os.path.exists(frame_folder):\n                continue\n           \n            frames = sorted([f for f in os.listdir(frame_folder) if f.endswith(\".jpg\")])\n            self.frame_paths.extend([os.path.join(frame_folder, f) for f in frames])\n            self.labels.extend([1 if 'anomaly' in video_folder.lower() else 0] * len(frames))  # Assign labels\n\n    def __len__(self):\n        return len(self.frame_paths)\n\n    def __getitem__(self, idx):\n        frame = Image.open(self.frame_paths[idx]).convert(\"RGB\")\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n\n        if self.transform:\n            frame = self.transform(frame)\n\n        return frame, label\n\n# Load dataset\nbase_folder = \"/kaggle/input/shanghaitech-anomaly-detection/dataset/mp\"\ndataset = FrameDataset(base_folder, transform)\n\n# Weighted Sampling to Handle Class Imbalance\nclass_counts = np.bincount(dataset.labels)\nweights = 1.0 / class_counts[dataset.labels]\nsampler = WeightedRandomSampler(weights, len(weights))\ndataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n\n# Define Vision Transformer Model\nclass ViTForAnomalyDetection(nn.Module):\n    def __init__(self):\n        super(ViTForAnomalyDetection, self).__init__()\n        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n       \n        # Fine-tuned fully connected layers\n        self.fc = nn.Sequential(\n            nn.Linear(1000, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 1)  # Output a single score for MIL\n        )\n       \n    def forward(self, x):\n        x = self.vit(x)\n        return self.fc(x)\n\n# Initialize model with GPU support\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ViTForAnomalyDetection().to(device)\nif torch.cuda.device_count() > 1:\n    model = torch.nn.DataParallel(model)\n\n# MIL Loss Implementation\nclass MILoss(nn.Module):\n    def __init__(self, lambda_reg=0.01):\n        super(MILoss, self).__init__()\n        self.lambda_reg = lambda_reg  # Regularization strength\n\n    def forward(self, outputs, labels):\n        \"\"\"\n        outputs: Model predictions (batch_size, 1)\n        labels: Ground truth labels (batch_size,), where 1 = anomaly, 0 = normal\n        \"\"\"\n        # Convert labels to -1 (normal) and 1 (anomaly)\n        labels = 2 * labels.float() - 1  # 0 -> -1, 1 -> 1\n\n        # Hinge loss term\n        hinge_loss = torch.mean(torch.clamp(1 - labels * outputs, min=0))\n\n        # L2 regularization term (using model parameters)\n        l2_reg = 0.0\n        for param in model.parameters():\n            l2_reg += torch.norm(param, p=2)\n\n        # Total MIL loss\n        mil_loss = hinge_loss + self.lambda_reg * l2_reg\n        return mil_loss\n\ncriterion = MILoss(lambda_reg=0.01)\n\n# Optimizer & Learning Rate Scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n\n# Training Loop\nnum_epochs = 2  # Increase epochs\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n   \n    for inputs, batch_labels in progress_bar:\n        inputs, batch_labels = inputs.to(device), batch_labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, batch_labels)\n        loss.backward()\n        optimizer.step()\n\n        # Update running loss\n        running_loss += loss.item()\n        progress_bar.set_postfix({\"MIL Loss\": loss.item()})\n   \n    lr_scheduler.step()\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - MIL Loss: {running_loss / len(dataloader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:46:17.221161Z","iopub.execute_input":"2025-03-09T13:46:17.221420Z","iopub.status.idle":"2025-03-09T18:48:05.464166Z","shell.execute_reply.started":"2025-03-09T13:46:17.221392Z","shell.execute_reply":"2025-03-09T18:48:05.463103Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n100%|██████████| 330M/330M [00:01<00:00, 193MB/s]  \nEpoch 1/2: 100%|██████████| 8569/8569 [2:37:42<00:00,  1.10s/it, MIL Loss=0.0337] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2] - MIL Loss: 2.0551\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/2: 100%|██████████| 8569/8569 [2:23:51<00:00,  1.01s/it, MIL Loss=0.0226]  ","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2] - MIL Loss: 0.0272\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2}]}